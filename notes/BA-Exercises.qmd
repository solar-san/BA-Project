---
title: "BA-Exercises"
author: "solar-san"
date-modified: "`r Sys.Date()`"
format:
  html:
    theme: github
    toc: true
    toc-location: right
    margin-header: "BA-Project_header.png"
    fig-align: center
    fig-width: 10
    fig-height: 8
    df-print: kable
    html-math-method: katex
    code-overflow: scroll
    code-copy: hover
    code-fold: show
    highlight-style: breeze
    tbl-cap-location: top
    fig-cap-location: top
    citations-hover: true
    footnotes-hover: true
    header-includes: |
      <meta name="author" content="solar-san">
      <meta name="image" property="https://raw.githubusercontent.com/solar-san/BA-Project/main/docs/figures/BA-Project_header.png">
      <meta 
      name="description"
      content="">
      <link rel="preconnect" href="https://fonts.googleapis.com">
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&family=Fira+Code&display=swap" rel="stylesheet">
mainfont: "Atkinson Hyperlegible"
monofont: 'Fira Code'
---

![](https://raw.githubusercontent.com/solar-san/BA-Project/main/docs/figures/BA-Project_header.png)

```{r setup}
#| echo: false
#| results: hide
#| warning: false
knitr::opts_chunk$set(
  echo = T
)

lib_list <- list(
  "tidyverse",
  "fpp3",
  "ggthemes",
  "patchwork",
  "quantreg",
  "broom"
)

lapply(
  lib_list,
  require,
  quietly = TRUE, 
  warn.conflicts = FALSE, 
  character.only = TRUE
)

theme_set(
  theme_tufte(
    base_size = 20,
    base_family = "Atkinson Hyperlegible"
  )
)

theme_update(
    legend.position = "top"
)

custom_color = scale_color_brewer(
  type = 'div',
  palette = 'Dark2'
)

tau_sel <- c(
        .1,
        .25,
        .5,
        .75,
        .9
      )
  
pathmaker <- function(filename, data_path = "/Users/themagician/Documents/DABS/Appunti/Business_Analytics/Lab3/") {
  file_path <- paste0(
    data_path,
    filename
  )
  return(
    file_path
  )
}
```


# Time Series Decomposition

## Reconstruct the calculations needed to derive the components in the multiplicative decomposition that was obtained for the Australian Gas Production.

The multiplicative decomposition obtained was a _classical multiplicative decomposition_:

```{r}
aus_production %>% 
  model(
    class_mult = classical_decomposition(
      Gas, 
      type = "m"
      )
    ) %>% 
  components() %>% 
  autoplot() +
  labs(
    title = "Classical Decomposition of Australian gas production"
  )
```

The model behind the multiplicative decomposition is the following:

$$
Y_t = T_t \times S_t \times R_t
$$

First, an appropriate _exponential smoothing_ has been applied to the series.

```{r}
#| fig-width: 12
#| fig-height: 12
aus_production %>% 
  gg_lag(
    Gas,
    geom = "point"
    ) +
  labs(
    title = 'Lag plot for Australian gas production'
  )
```

We can observe a $k=4$ seasonal pattern. This can be confirmed by an ACF plot:

```{r}
#| fig-height: 6
aus_production %>% 
  ACF(Gas) %>% 
  autoplot +
  labs(
    title = "ACF plot for Australian gas production"
  )
```

If no argument are passed, a _symmetric_ window with equal weights is used to obtain the $T_t$ (trend component). The following step is to de-trend the series:

$$
\frac{y_t} {T_t}
$$

The seasonal component is computed by taking the average of all the de-trended values for each for that season. The decomposition is multiplicative: hence, the individual seasonal term are adjusted to ensure that they sum up to $m$. The remainder component is then computed by dividing by the trend and seasonal component:

$$
R_t = \frac{y_t}{ S_t  T_t}
$$

To conclude, de-seasonalize the series:

$$
\frac{y_t}{S_t}
$$
## Compute a 5-MA and 9-MA for the oil prices in the `prices` dataset and overlay them to the original data ensuring that suitable labels are used to identify the different fits

```{r}
prices %>% 
  mutate(
    '5-MA' = slider::slide_dbl(
      oil,
      mean,
      .before = 2,
      .after = 2,
      complete = TRUE
    ),
    '9-MA' = slider::slide_dbl(
      oil,
      mean,
      .before = 4,
      .after = 4,
      complete = TRUE
    )
  ) %>% 
  na.omit() %>% 
  ggplot(
    aes(
      x = year
    )
  ) +
  geom_line(
    aes(
      y = oil
    ),
    color = "gray90"
  ) +
  geom_line(
    aes(
      y = `5-MA`,
      color = "5-MA"
    )
  ) +
  geom_line(
    aes(
      y = `9-MA`,
      color = "9-MA"
    )
  ) +
  custom_color +
  labs(
    title = 'Moving Averages of oil prices'
  )
```

## Decompose the US Retail sector time series. Use an additive classical decomposition. Plot the components and comment on possible issues in the resulting decomposition.

```{r}
us_retail <- 
  us_employment %>%
    filter(
      Title == "Retail Trade", 
      year(Month) >= 1980
      ) 
```

```{r}
us_retail %>% 
  model(
    classical_decomposition(Employed)
  ) %>% 
  components() %>% 
  autoplot +
  labs(
    title = 'Classical Decomposition of employed in US retail'
  )
```

The main assumption in this case that the seasonal term is assumed as constant: the remainder term is a clear indication of eteroskedasticity and this assumption needs to be reconsidered.

```{r}
us_retail %>% 
  autoplot(Employed) +
  labs(
    title = "Employment in the US retail sector"
  )
```

From the original series we can see that the magnitude of the seasonal variation depends on the level of the series; therefore, a multiplicative decomposition might be more appropriate.

## Derive the numerical values for the multiplicative triple exponential smoothing ("Triple_Mult") of the Australian beer production model seen above.

```{r}
aus_beer <- aus_production %>%
  filter(year(Quarter) >= 2000) %>% 
  select(Beer)

fit <- aus_beer %>% 
  model(
    Triple_Mult = ETS(
      Beer ~ trend("A")+season("M")+error("M")
      )
    )

fit %>% 
  augment() %>% 
  select(
    Quarter, 
    .fitted
  ) %>% 
  head()
```


## Focus on the Tobacco production in Australia: the values are contained in the `aus_production` dataset: discuss whether a single, double or triple exponential smoothing would be more appropriate to smooth this time series. Compare the 20-step ahead forecast obtained when using a triple exponential smoothing with a damped and non-damped trend. 

```{r}
aus_tobacco <- aus_production %>% 
  select(Tobacco) %>% 
  na.omit()

aus_tobacco %>% 
  autoplot(Tobacco)  +
  labs(
    title = "Australian tobacco production"
  )
```

The dataset shows a strong seasonal and trend-cycle component: hence, simple exponential smoothing is _not_ appropriate, as double exponential smoothing, because they cannot deal with the seasonal component. _Triple Exponential Smoothing_ (Holt-Winter's method) is the preferred choice in this context.

```{r}
fit <- aus_tobacco %>% 
  model(
    linear = ETS(
      Tobacco ~ error('A') + season('A') + trend('A')
      ),
    damped = ETS(
      Tobacco ~ error('A') + season('A') + trend('Ad')
      ),
  )

fc <- fit %>% 
  forecast(
    h = 20
  )

fc %>% 
  autoplot(
    aus_tobacco,
    level = NULL
  ) +
  custom_color +
  labs(
    title = "Damped and linear ETS forecasts \n for the Australian tobacco production"
  )
```

## Focus on the `global_economy` dataset: pick a country (say France) and produce a simple exponential smoothing forecast for the country GDP. Discuss whether a double exponential smoothing or triple exponential smoothing would be suitable to use for smoothing the time series. 

```{r}
fit <- global_economy %>% 
  filter(
    Country == 'Japan'
  ) %>% 
  model(
    ETS(
      GDP ~ error('A') + season('N') + trend('N')
    )
  )

fc <- fit %>% 
  forecast(
    h = 10
  )
```


```{r}
fc %>% 
  autoplot(
    global_economy %>% 
  filter(
    Country == 'Japan'
  ),
  level = NULL,
  color = "indianred4"
  ) +
  labs(
    title = "Simple exponential smoothing forecast for Japan GDP"
  )
```

A double exponential smoothing would be more effective, as we have a clearly trended series:

```{r}
fit <- global_economy %>% 
  filter(
    Country == 'Japan'
  ) %>% 
  model(
    ETS(
      GDP ~ error('A') + season('N') + trend('A')
    )
  )

fc <- fit %>% 
  forecast(
    h = 10
  )
```

```{r}
fc %>% 
  autoplot(
    global_economy %>% 
  filter(
    Country == 'Japan'
  ),
  level = NULL,
  color = "indianred4"
  ) +
  geom_line(
    aes(
      y = .fitted,
      col = "Smoothed Series"
    ),
    data = fit %>% 
      augment
  ) +
  labs(
    title = "Double exponential smoothing forecast for Japan GDP"
  )
```

# Quantile Regression

## Obtain the dataset `bodyfat` in which the weight and the height of a random sample of 255 men are stored: 

```{r}
urlLocation <- "https://dasl.datadescription.com/download/data/3079"
bodyfat <- read.table(urlLocation, header=TRUE)
bodyfat <- bodyfat[,c("Weight","Height")]
```

```{r}
bodyfat %>% str
```

## We wish to construct a regression model in which the Weight of a man is regressed against its height. Use a quantile regression framework to answer (among others) the following questions.

### What is the effect of Weight on Height: does this appear to change for different quantiles? Compute the estimated coefficients and provide a visual display.

Fitting the QRM model:

```{r}
bodyfat_qrfit <- rq(
  Weight ~ Height,
  data = bodyfat,
  tau = c(
    .1,
    .25,
    .5,
    .75,
    .9
  )
)
```

```{r}
bodyfat_qrfit %>% 
  tidy()
```

```{r}
bodyfat_qrfit %>% 
  summary(
    se = "boot",
    R = 1201
  )
```

```{r}
ggplot(
  bodyfat,
  aes(
    x = Height,
    y = Weight
    )
) +
  geom_point() +
  geom_quantile(
    quantiles = c(
      .1,
      .25,
      .5,
      .75,
      .9
    )
  )
```

```{r}
bodyfat_coeff <- bodyfat_qrfit %>% 
  coefficients()

ggplot() +
  geom_line(
    aes(
      x =  c(
        .1,
        .25,
        .5,
        .75,
        .9
      ),
      y = bodyfat_coeff[2,]
    )
  ) +
  labs(
    title = "Weight ~ Height QRM coefficients",
    x = "Quantiles",
    y = "Slopes"
  )
```

While indeed the effect is different for different quantiles, the slops are not different in a statistically significant way.

```{r}
anova(bodyfat_qrfit)
```

The main variation among the quantiles is related to the _intercept_, which is clearly varying. Up until the 25% quantile the average effect of height on weight is decreasing; this relationship is inverted from the 25% to the 90% quantile, in which higher heights are associated on average with higher weights.

```{r}
ggplot() +
  geom_line(
    aes(
      x =  c(
        .1,
        .25,
        .5,
        .75,
        .9
      ),
      y = bodyfat_coeff[1,]
    )
  ) +
  labs(
    title = "Weight ~ Height QRM coefficients",
    x = "Quantiles",
    y = "Intercepts"
  )
```

### Compute the 95% confidence interval for the slope parameter of the median regression. Also indicate whether there is evidence that its value is null.

```{r}
bodyfat_medianfit <- rq(
  Weight ~ Height,
  data = bodyfat
  )
```

```{r}
bodyfat_medianfit %>% 
  summary(
    se = "boot"
  )
```
The p-value of the slope coefficient significance test is $\approx$ 0; the observed data points against the null hypothesis, hence the slope parameter is, with a given confidence, different than zero.

We will use bootstrapped coefficients to compute a 95% confidence interval for the slope:

```{r}
qr_boot <- boot.rq(
  x = cbind(
    1, 
    bodyfat$Height
    ),
  y = bodyfat$Weight,
  tau = 0.5, 
  R = 2000,
  coef = bodyfat_coeff
  )
```

```{r}
t(apply(qr_boot$B, 2, quantile, c(0.025,0.975)))[2, ]
```

### Produce some plots which explore whether the scale or shape of the Weight distribution change as a function of Height. 

```{r}
qs <- bodyfat_qrfit %>% 
  augment(
    newdata = expand_grid(
      Height = seq(
        64.00,
        77.75
        )
      )
    ) %>% 
  pivot_wider(
    names_from  =.tau, 
    values_from = .fitted
    ) %>% 
  mutate(
    QSC025 = `0.75` - `0.25`,
    QSK010 = (`0.9` - `0.5`)/(`0.5` - `0.1`) - 1
  )
```

```{r}
ggplot(qs) + 
  geom_line(
    aes(
      Height, 
      QSC025
      )
    )
```

The spread of the weight distribution is slightly decreasing as height decreases.

```{r}
ggplot(qs) + 
  geom_line(
    aes(
      Height, 
      QSK010
      )
    )
```

A value greater than zero indicates right-skewness and a value less than 0 indicates left-skewness: in this case, we have a slightly right-skewed weight distribution that becomes more symmetrical as the height increases.

### Is there strong evidence against the distribution of Weight to be different for different levels of Height? 

Based on the available data, the result is ambiguous; while indeed the position of the distribution changes with height, as it is more common for taller people to weight more, the slope of the effect of the regressor on the regressand and the overall shape and scale of the distribution, as its skewness, is not heavily impacted (if not impacted at all); hence, only a weak evidence in favor of this difference can be derived from the observed data.

## Carry out a single predictor quantile regression analysis for the Munich rents dataset investigating the effect of `area` on `rent` and on `rentsq`. Answer questions similar to those presented in Exercise 1. 

```{r}
rents_sel <- readr::read_table(
  pathmaker(
    "data/rent99.raw"
  ),
  col_types = cols(
    rent = col_double(),
    rentsqm = col_double(),
    area = col_double(),
    yearc = col_double(),
    location = col_factor(),
    bath = col_factor(),
    kitchen = col_factor(),
    cheating = col_logical(),
    district = col_factor()
  )
) %>% 
  select(area, rent, rentsqm)
```

```{r}
rents_sel %>% summary
```

```{r}
#|column: page
p1 <- rents_sel %>% 
  ggplot() +
  geom_histogram(
    aes(
      area
      ),
    fill = "indianred"
    ) 
p2 <- rents_sel %>% 
  ggplot() +
  geom_histogram(
    aes(
      rent
      ),
    fill = "springgreen4"
    ) 
p3 <- rents_sel %>% 
  ggplot() +
  geom_histogram(
    aes(
      rentsqm
      ),
    fill = "darkslategray4"
    ) 

p1 + p2 + p3

```

```{r}
rent_qr <- rq(
  rent ~ area,
  tau = tau_sel,
  data = rents_sel
)
```

```{r}
rentsqm_qr <- rq(
  rentsqm ~ area,
  tau = tau_sel,
  data = rents_sel
)
```

```{r}
rent_qr %>% 
  summary(
    se = 'boot'
    )
```

```{r}
rentsqm_qr %>% 
  summary(
    se = 'boot'
  )
```

```{r}
#| column: page
p1 <- rents_sel %>% 
  ggplot(
    aes(
      x = area,
      y = rent
    )
  ) +
  geom_point(
    col = 'grey30',
    alpha = .6
  ) +
  geom_quantile(
    quantiles = tau_sel,
    color = "darkorange"
  ) +
  labs(
    title = 'Rent ~ Area'
  )
p2 <- rents_sel %>% 
  ggplot(
    aes(
      x = area,
      y = rentsqm
    )
  ) +
  geom_point(
    col = 'grey30',
    alpha = .6
  ) +
  geom_quantile(
    quantiles = tau_sel,
    color = "limegreen"
  ) +
  labs(
    title = 'Rentsqm ~ Area'
  )
p1 + p2
```

```{r}
rent_qr_coef <- rent_qr %>% 
  coef()
rentsqm_qr_coef <- rentsqm_qr %>% 
  coef()
```

```{r}
#|column: page
p1 <- ggplot() +
  geom_line(
    aes(
      x = tau_sel,
      y = rent_qr_coef[2, ]
    )
  ) +
  labs(
    title = 'Rent ~ Area',
    x = 'Quantiles',
    y = 'Slope'
  )
p2 <- ggplot() +
  geom_line(
    aes(
      x = tau_sel,
      y = rentsqm_qr_coef[2, ]
    )
  ) +
  labs(
    title = 'Rentsqm ~ Area',
    x = 'Quantiles',
    y = 'Slope'
  )
p1 + p2 + plot_annotation('Slopes coefficients for different quantiles')
```

```{r}
#|column: page
p1 <- ggplot() +
  geom_line(
    aes(
      x = tau_sel,
      y = rent_qr_coef[1, ]
    )
  ) +
  labs(
    title = 'Rent ~ Area',
    x = 'Quantiles',
    y = 'Intercepts'
  )
p2 <- ggplot() +
  geom_line(
    aes(
      x = tau_sel,
      y = rentsqm_qr_coef[1, ]
    )
  ) +
  labs(
    title = 'Rentsqm ~ Area',
    x = 'Quantiles',
    y = 'Intercepts'
  )
p1 + p2 + plot_annotation('Intercepts coefficients for different quantiles')
```

```{r}
anova(rent_qr)
```
```{r}
anova(rentsqm_qr)
```
Slopes are significantly different between the quantiles. We can see that the relationships modelled by the different models are uneven and that the median works as a tipping point for both the intercept of the `rent ~ area` model, reaching a maximum and then decreasing, and for the slope of the `rentsqm ~ area` model, reaching a minimum and increasing.

We will use bootstrapped coefficients to compute a 95% confidence interval for the slope.

```{r}
qr_boot <- boot.rq(
  x = cbind(
    1, 
    rents_sel$area
    ),
  y = rents_sel$rent,
  tau = 0.5, 
  R = 2000,
  coef = rent_qr_coef
  )
```

```{r}
t(apply(qr_boot$B, 2, quantile, c(0.025,0.975)))[2, ]
```

```{r}
qr_boot <- boot.rq(
  x = cbind(
    1, 
    rents_sel$area
    ),
  y = rents_sel$rentsqm,
  tau = 0.5, 
  R = 2000,
  coef = rentsqm_qr_coef
  )
```

```{r}
t(apply(qr_boot$B, 2, quantile, c(0.025,0.975)))[2, ]
```

There is no evidence on either slope being significantly null.

```{r}
qs <- rent_qr %>% 
  augment(
    newdata = expand_grid(
      area = seq(
        20,
        160
        )
      )
    ) %>% 
  pivot_wider(
    names_from  =.tau, 
    values_from = .fitted
    ) %>% 
  mutate(
    QSC025 = `0.75` - `0.25`,
    QSK010 = (`0.9` - `0.5`)/(`0.5` - `0.1`) - 1
  )
```

```{r}
ggplot(qs) + 
  geom_line(
    aes(
      area, 
      QSC025
      )
    )
```

The spread of the `rent` distribution is monotonically increasing with the `area`.

```{r}
ggplot(qs) + 
  geom_line(
    aes(
      area, 
      QSK010
      )
    )
```

We can observe that the skewness of the `rent` distribution is heavily affected by the `area` variable, changing from left-skewed to symmetric to right-skewed.

```{r}
qs <- rentsqm_qr %>% 
  augment(
    newdata = expand_grid(
      area = seq(
        20,
        160
        )
      )
    ) %>% 
  pivot_wider(
    names_from  =.tau, 
    values_from = .fitted
    ) %>% 
  mutate(
    QSC025 = `0.75` - `0.25`,
    QSK010 = (`0.9` - `0.5`)/(`0.5` - `0.1`) - 1
  )
```

```{r}
ggplot(qs) + 
  geom_line(
    aes(
      area, 
      QSC025
      )
    )
```

The spread of `rentsqm` is slightly decreasing with area.

```{r}
ggplot(qs) + 
  geom_line(
    aes(
      area, 
      QSK010
      )
    )
```

The right-skewness of the `rentsqm` variable is exponentially increasing with `area`: as the area increases, the right-hand tail of the distribution becomes wider; this can be attributed to the surge of outliers in the distribution.

We can definitely conclude that both location, shape and scale of the regressands are affected by the regressor variable.

## Use the `incomeEx` dataset. What is the effect of Age on Income? 

```{r}
incomeEx <- readr::read_csv(
    pathmaker(
        "data/incomeSurvey.csv"
      )
    )
incomeEx$income <- incomeEx$cinc/1000
```

```{r}
incomeEx %>% 
ggplot(
  aes(
      x = age,
      y = income
    )
) +
  geom_point(
    alpha = .2,
    col = "grey20"
  ) +
  geom_quantile(
    quantiles = tau_sel,
    col = "darkorange"
  )
```
The relationship appears to be non linear; however, it could be approximated by a linear relationship: `income` is decreasing with `age`, although a closer analysis is warranted.

## Is this the same for all quantiles of the distribution? 

```{r}
simple_fit <- rq(
  income ~ age,
  data = incomeEx,
    tau = c(
    .1,
    .25,
    .5,
    .75,
    .9
  )
)
```

```{r}
simple_fit %>% 
  summary(
    se = 'boot'
  )
```

```{r}
anova(simple_fit)
```
The relationship is indeed different across the quantiles; both intercepts and slopes are changing.

```{r}
simple_fit_coeff <- simple_fit %>% 
  coef()
```

```{r}
ggplot() +
  geom_line(
    aes(
      x =  c(
        .1,
        .25,
        .5,
        .75,
        .9
      ),
      y = simple_fit_coeff[1,]
    )
  ) +
  labs(
    title = "Income ~ Area QRM coefficients",
    x = "Quantiles",
    y = "Intercept"
  )
```

```{r}
ggplot() +
  geom_line(
    aes(
      x =  c(
        .1,
        .25,
        .5,
        .75,
        .9
      ),
      y = simple_fit_coeff[2,]
    )
  ) +
  labs(
    title = "Income ~ Area QRM coefficients",
    x = "Quantiles",
    y = "Slopes"
  )
```

## Construct models in which the relationship is allowed to be different depending of the race and education level of the household head. Provide a graphical display which presents the estimated models. Is there enough evidence to indicate that the effect of Age on Income is different for different races/education level? Specify the statistical test that would be carried out.

`white` will be set as the baseline `eth` for a better interpretation of the coefficients: hence, the average level corresponding to the intercept is `college`^[For the `ced` variable.] and `white`.

```{r}
incomeEx$eth <-  incomeEx$eth %>% as.factor()
incomeEx$eth <- relevel(incomeEx$eth, ref = "white")
```

```{r}
#| column: page
incomeEx %>% 
  ggplot(
    aes(
      x = age,
      y = income
    )
  ) +
  geom_point(
    col = "grey70",
    alpha = .7
  ) +
  geom_quantile(
    formula = y ~ x,
    quantiles = tau_sel,
    col = 'darkred'
  ) +
  facet_grid(
    rows = vars(ced),
    cols = vars(eth)
  ) +
  labs(
    title = 'Income ~ Age for different Education levels and Ethnicities'
  )
  
```

This set of charts already allows to spot variation of the response shape and distribution across the quantiles; in particular, there is a noticeable difference between the quantile regressions for `white` and `black` for people having attended `college`. Moreover, we can notice that there are far less data points for `asian`; this might affect the standard errors and hypothesis tests. 

```{r}
income_extended <- rq(
  income ~ age + eth + ced,
  data = incomeEx,
  tau = tau_sel
)
```

```{r}
income_extended %>% 
  summary(
    se = 'boot'
  )
```

A table of the coefficients confirms that both intercept and slope change, with the most noticeable effects on the higher quantiles.

```{r}
income_extended %>% coef
```
```{r}
anova(
  income_extended
)
```

There is a strong evidence in favor of the hypothesis that education and ethnicity influence the effect of `age` on `income`. Ethnicity at most levels of is statistically significant, each pointing at a lower average level; however, the significance is uneven, as in some quantiles, given the reference (baseline) scenario of `eth == 'white'`, either `'asian'` or '`hispanic'` or both do not seem to have statistical significance, indicating that only the `black` ethnicity is consistently influencing the effect of `age` on `income`, exception made for the lowest decile. Education is consistently significant across all the quantiles, implicating that not graduating form college corresponds to a lower average income, therefore affecting the relationship of `income`and `age` as it changes the level of their relationship. We can also notice a strong difference in the slopes.

# Bootstrap

## For the Munich data compute confidence intervals of the mean rental price for locations without central heating both using theory and a bootstrap-based approach.  

```{r}
rents_full <- readr::read_table(
  pathmaker(
    "data/rent99.raw"
  ),
  col_types = cols(
    rent = col_double(),
    rentsqm = col_double(),
    area = col_double(),
    yearc = col_double(),
    location = col_factor(),
    bath = col_factor(),
    kitchen = col_factor(),
    cheating = col_logical(),
    district = col_factor()
  )
)
```

> Method 1:

```{r}
ci_mean <- lm(
    rent ~ cheating,
    data = rents_full %>% filter(cheating == FALSE)
  ) %>% 
  confint()

ci_mean[1, ]
```

> Method 2:

```{r}
rents_full %>% 
  filter(cheating == FALSE) %>% 
  summarise(
    mean_rent = mean(rent),
    se = sd(rent)/sqrt(n()),
    lower = mean_rent - qnorm(.975)*se,
    upper  = mean_rent + qnorm(.975)*se

  )
```

> Bootstrap:

```{r}
boot_size <- 2000
bootstrapped_mean <- rep(NA, boot_size)

rent_nocheating <- rents_full %>% 
    filter(
      cheating == FALSE
    ) %>% 
    select(
      rent
      )

for(i in 1:boot_size) {
  
  bootstrapped_mean[i] <- mean(
    sample(
    rent_nocheating$rent,
    size = 200,
    replace = T
    )
  )
}

quantile(bootstrapped_mean, probs = c(.025, .975), na.rm = T)
```

For the same significance level of $5%$, the bootstrap method yields a larger interval; nevertheless, it is remarkably similar to the interval computed by applying asymptotic theory.

## Take the `engel` data. Estimate a quantile regression models for $\tau = c(0.1,0.5,0.9)$. Derive bootstrap-based sampling distributions for the regression model parameters. Compare the estimated standard error derived for your bootstrap distribution to the ones obtained using `summary` from the `quantreg` package. 

```{r}
data(engel)
```

```{r}
engel_fit <- rq(
  foodexp ~ income, 
  data = engel
  )
```

```{r}
engel_fit %>% 
  summary(
    se = 'boot'
  ) %>% 
    coefficients() %>%
      subset(
        select = "Std. Error"
        )
```


```{r}
boot_size <- 2000
boot_engel_coeff <- matrix(NA, boot_size, 2)

for(i in 1:boot_size) {
  boot_sample <- sample(
    seq(
      1, 
      nrow(engel)
      ), 
    replace = TRUE, 
    size = nrow(engel)
    )
  boot_engel_coeff[i, ] <- rq(
    foodexp ~ income, 
    data = engel[boot_sample, ]
    ) %>% 
    coefficients() 
}

tibble(
  Intercept = boot_engel_coeff[, 1],
  Slope = boot_engel_coeff[, 2]
) %>%
  summarise(
    SE_intercept = sd(Intercept),
    SE_Slope = sd(Slope)
  )
```

## Take the `engel` data. Make a plot which shows the point estimate and bootstrap based intervals for the slope of different quantile regression models for values of $\tau$ = `seq(0.1, 0.9, by = 0.05)`.

```{r}
tau_seq <- seq(
    0.1, 
    0.9, 
    by = 0.05
    )
names(tau_seq) <- as.character(
  paste(
    'q =',
    seq(
      0.1, 
      0.9, 
      by = 0.05
      )
    )
  )
```

```{r}
engel_mqr <- rq(
  foodexp ~ income,
  data = engel,
  tau = tau_seq
)
```

```{r}
boot_intervals <- function(tau, R = 2000) {
  
  qr_boot <- boot.rq(
    x = cbind(
      1, 
      engel$income
      ),
    y = engel$foodexp,
    tau = tau, 
    R = R
  )
  res <- t(apply(qr_boot$B, 2, quantile, c(0.025,0.975)))[2, ]
  
  return(res)
}
```

```{r}
engel_slope_ci <- lapply(tau_seq, boot_intervals) %>% as_tibble()
engel_slope_ci
```

```{r}
ggplot(
  data = tau_seq %>% as_tibble,
  aes(
    x = tau_seq,
    y = engel_mqr$coefficients[2,]
  )
) +
  geom_line(
    col = "grey60"
  ) +
  geom_pointrange(
    aes(
      ymin = engel_slope_ci[1, ] %>% t(),
      ymax = engel_slope_ci[2,] %>% t()
    )
  ) +
  labs(
    title = "Slope confidence intervals for Engel data",
    x = expression(tau),
    y = expression(hat(beta)^(tau))
  )
```

