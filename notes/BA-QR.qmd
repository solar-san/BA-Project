---
title: "Quantile Regression"
author: "solar-san"
date-modified: "`r Sys.Date()`"
format:
  html:
    theme: github
    toc: true
    toc-location: right
    margin-header: "BA-Project_header.png"
    fig-align: center
    fig-width: 10
    fig-height: 8
    html-math-method: katex
    code-overflow: scroll
    code-copy: hover
    code-fold: show
    highlight-style: breeze
    tbl-cap-location: top
    fig-cap-location: top
    citations-hover: true
    footnotes-hover: true
    header-includes: |
      <meta name="author" content="solar-san">
      <meta name="image" property="https://raw.githubusercontent.com/solar-san/BA-Project/main/docs/figures/BA-Project_header.png">
      <meta 
      name="description"
      content="Notes on quantile regression for business analysts. It contains a self-contained introduction tje topic, with R code snippets and the necessary mathematical and statistical notation.">
      <link rel="preconnect" href="https://fonts.googleapis.com">
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&family=Fira+Code&display=swap" rel="stylesheet">
mainfont: "Atkinson Hyperlegible"
monofont: 'Fira Code'
---

![](https://raw.githubusercontent.com/solar-san/BA-Project/main/docs/figures/BA-Project_header.png)

```{r setup}
#| echo: false
#| results: hide
#| warning: false
knitr::opts_chunk$set(
  echo = T
)

  
pathmaker <- function(filename, data_path = "/Users/themagician/Documents/DABS/Appunti/Business_Analytics/Lab3/") {
  file_path <- paste0(
    data_path,
    filename
  )
  return(
    file_path
  )
}


lib_list <- list(
  "tidyverse",
  "ggthemes",
  "patchwork"
)

lapply(
  lib_list,
  require,
  quietly = TRUE, 
  warn.conflicts = FALSE, 
  character.only = TRUE
)

theme_set(
  theme_tufte(
    base_size = 20,
    base_family = "Atkinson Hyperlegible"
  )
)

theme_update(
    legend.position = "top"
)
```

# Introduction

> What is _Business Analytics_? It is an applied discipline, tasked with gaining insight into business operations and helping to make better, fact-based decisions: a basic pillar of being _data-driven_. It combines Statistics, Computer Sciences, Management Science, Operational Research, and much more.

It has three main components:

1. __Descriptive analytics__: providing insight into business questions by summarizing and visualizing observed data. Typically based on simple summaries and charts^[Any predictive or prescriptive model is based on some steps of _descriptive analytics_.].
2. __Predictive analytics__: providing insight into the possible future by extrapolating patterns found in the historical data. Typically making use of statistical or machine learning predictive models (remember the Statistical Learning and Data Analytic courses).
3. __Prescriptive analytics__: providing ways to make the best possible decisions based on the available information.

> What is the role of Quantile Regression in Business Analytics?

The Ordinary-Least-Squares (OLS) based linear regression is a well-known approach when it comes to model relationships between variables, such as:

$$
Y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{p i + \epsilon_i}
$${#eq-multlinreg}

There are fundamental assumptions behind this model:

- Independence of observations and error terms.
- The error terms are identically distributed.
- We have _homoskedasticity_ and _zero mean_^[This last one, however, is not strictly necessary.].
- Normality of errors, as in $\epsilon \stackrel{iid} {\sim} N(0, \sigma^2_{\epsilon})$^[This assumption allows for inference on the model parameters.].

The main focus is to estimate the _mean_ of the distribution: all the assumptions lead to the following formula.

$$
\mathbb{E} [Y_i \vert X = x_i] = \beta_0 + \beta_1 x_1 + ... + \beta_p x_p
$${#eq-condlinreg}

> Quantile regression allows to deal with data that cannot be described with a _normal distribution_ and that can be summarised effectively using the _mean_^[Warning: the mean is _not_ a robust indicator of position.].

The main consequence of having homoskedastic and normal errors are:

- Symmetry.
- If the mean and scaled are known, we can assume that we know the whole distribution. Therefore, knowing _how the mean changes_ explains _all the changes in the distribution_.

However, this is often not the case: 
```{r}
incomeEx <- readr::read_csv(
    pathmaker(
        "data/incomeSurvey.csv"
      )
    )
incomeEx$income <- incomeEx$cinc/1000
ggplot(
  incomeEx
  ) +
  geom_histogram(
    aes(
      income
      ),
    # color = "grey50", 
    fill  = "grey70"
    ) + 
  geom_hline(
      yintercept = seq(
        0,
        2000,
        500
      ),
      color = "white"
  ) +
  labs(
    x = "Income",
    title = "Income (100s USD)"
    )
```

:::{callout.important}
Many variables are _not_ symmetric. Moreover, we are often not only interested in the _mean_, but in understanding _extremes_. Since linear regression model cannot give the full description of the distribution and everything is described by its mean, we need an alternative Framework.
:::

We do not need to forget that linear regression is appropriate for several applications and comes with many practical and theoretical reason to explain its widespread adoption. For example, it is computationally feasible and easy to implement and can be adapted to handle heteroskedasticity and robustness. Moreover, it can be _generalized_ to handle the non-gaussian case and even non-linearity^[Generalized Linear Models.].

# Quantiles 

_Quantiles_ are defined mathematically as:

$$
Q(p) = \mathrm{inf} \{ x: P(X \leq x) \geq p \}
$${#eq-quantile}

This is strictly related to the _cumulative distribution function_. The quantile of order $\alpha$ can also be interpred as that point in the distribution for which you have a probability $\alpha$ of observing a value less than that quantile^[In other words, it determines a specific point in the distribution. For example, the _median_ is the quantile of order 0.5: you have a $50%$ probability of observing a value lower than the median.].

We can compute a set of quantiles to help prove the point. Note that the mean of the distribution is `r mean(incomeEx$income)`.

```{r}
pquant <- quantile(incomeEx %>% pull(income), c(0.1,0.25,0.5,0.75,0.9))
pquant
```

There is a noticeable positive difference between _median_ and _mean_, indicating a right-skewed distribution. Computing such differences helps in understanding the _shape_ of our distribution.

We notice that the difference between the 75th and the 50th quantile is larger than the difference between the 50th and the 25th percentile: this is an indication of an asymmetry in the distribution. The same goes when comparing the the more extreme tails (e.g. the 10th and 90th quantile): 

```{r}
pquant[4]- pquant[3]; pquant[3] - pquant[2]  
pquant[5]- pquant[3]; pquant[3] - pquant[1]
```

Quantiles are not only _theoretical_: we can build an _Empirical Cumulative Distribution_ function that describes the cumulative _frequencies_ of the observed values in our data.

For example, for an $iid$ sample:

$$
\hat F = \frac{\mathrm{number \ of \ observations} \leq t}{n}
$${#eq-ECDF}

