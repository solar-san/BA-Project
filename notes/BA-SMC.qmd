---
title: "Simulation and Monte Carlo Analysis"
author: "solar-san"
date-modified: "`r Sys.Date()`"
format:
  html:
    theme: github
    toc: true
    toc-location: right
    margin-header: "BA-Project_header.png"
    fig-align: center
    fig-width: 10
    fig-height: 8
    df-print: paged
    html-math-method: katex
    code-overflow: scroll
    code-copy: hover
    code-fold: show
    highlight-style: breeze
    tbl-cap-location: top
    fig-cap-location: top
    citations-hover: true
    footnotes-hover: true
    header-includes: |
      <meta name="author" content="solar-san">
      <meta name="image" property="https://raw.githubusercontent.com/solar-san/BA-Project/main/docs/figures/BA-Project_header.png">
      <meta 
      name="description"
      content="Notes on simulation and Monte Carlo analysis for business analysts. It contains a self-contained introduction the topic, with R code snippets and the necessary mathematical and statistical notation.">
      <link rel="preconnect" href="https://fonts.googleapis.com">
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&family=Fira+Code&display=swap" rel="stylesheet">
mainfont: "Atkinson Hyperlegible"
monofont: 'Fira Code'
---

![](https://raw.githubusercontent.com/solar-san/BA-Project/main/docs/figures/BA-Project_header.png)

```{r setup}
#| echo: false
#| results: hide
#| warning: false
knitr::opts_chunk$set(
  echo = T
)

  
pathmaker <- function(filename, data_path = "/Users/themagician/Documents/DABS/Appunti/Business_Analytics/Lab3/") {
  file_path <- paste0(
    data_path,
    filename
  )
  return(
    file_path
  )
}


lib_list <- list(
  "tidyverse",
  "quantreg",
  "broom",
  "ggthemes",
  "patchwork"
)

lapply(
  lib_list,
  require,
  quietly = TRUE, 
  warn.conflicts = FALSE, 
  character.only = TRUE
)

theme_set(
  theme_tufte(
    base_size = 20,
    base_family = "Atkinson Hyperlegible"
  )
)

theme_update(
    legend.position = "top"
)
```

# Introduction {#sec-intro}

> What is _Business Analytics_? It is an applied discipline, tasked with gaining insight into business operations and helping to make better, fact-based decisions: a basic pillar of being _data-driven_. It combines Statistics, Computer Sciences, Management Science, Operational Research, and much more.

It has three main components:

1. __Descriptive analytics__: providing insight into business questions by summarizing and visualizing observed data. Typically based on simple summaries and charts^[Any predictive or prescriptive model is based on some steps of _descriptive analytics_.].
2. __Predictive analytics__: providing insight into the possible future by extrapolating patterns found in the historical data. Typically making use of statistical or machine learning predictive models (remember the Statistical Learning and Data Analytic courses).
3. __Prescriptive analytics__: providing ways to make the best possible decisions based on the available information.

> What is the role of Monte Carlo simulation in Business Analytics?

The main reason for adoptin a simulation-based approach is __uncertainty__: it is what makes decision-making difficult, hence we need tools to _quantify_ and _account for_ uncertainty. Simulation-based approaches are a set of estimation methods used to quantify statistical uncertainty.

> _Monte Carlo_^[The term _Monte Carlo_ refers to a range of methods in which _statistical sampling_ is employed to approximate solutions to quantitative problems; the name Monte Carlo is related to the Monte Carlo _casino_ in Monaco where randomness is king.] _simulation_ is a computer-based method to quantify, visualize, and assess uncertainty to evaluate its impact on decision-making. This class of methods is also known as _Risk Analysis_ or _Static Simulation_ models.

While a closed-form solution is sometimes available for a large set of problems, provided that some quantities are known. This is often not the case. For example, _profits_ are a function of _revenues_ and _costs_: if the two latter quantites are known, then we can easily compute the _profits_; but revenues and costs are typically _not_ known precisely, although it is possible to make some _probabilistic assessment_ on the range of possible values.

The Monte Carlo simulation method is employed to evaluate the _properties of solutions_ in scenarios where system inputs exhibit _stochastic_ variations, proving crucial for _decision-making_ and _risk analysis_. Additionally, it serves as a valuable tool for quantifying uncertainty in _estimation_ procedures, particularly in situations where mathematical derivations, integrals, and optimization procedures may be intricate. This approach is also instrumental in exploring and validating the properties of statistical machine learning estimation procedures.

# Decision-making and Uncertainty

> Decision making is a fundamental and unavoidable aspect of business intelligence and analytics. Ideally, we wish decision to be logically sound and justifiable. Hence, a decision-making _procedure_ or _model_ is required.

The following procedure is based on a simple princile: defining _clearly_ the decision problem.

1. Translate the _decision_ problem into a _conceptual_ model.
2. Convert the _conceptual_ model into a _mathematical_ model that can be handled using mathematical reasoning.
3. Once the mathematical model is defined we can use it to assess whether the outcome is _robust_ to changes in the assumptions.

## Example: A Decision Model for Profit {#sec-profitex1}

> This model is tasked with computing the profit of a small company.

The simplest function that computes profits is `Profit = revenue - cost`. We can expand this mapping by considering that:

- _Revenues_ depend on the quantity that is sold and on the unit price.
- _Costs_ depend on the quantity that is produced, on the unit cost and on the fixed
costs.

These considerations lead to the following model:

$$
\mathrm{Profit} = p \times min\{D, Q\} - (F + cQ) 
$${#eq-profitmodel}

- $p$ is the _unit price_.
- $Q$ is the _quantity produced_.
- $F$ is the _fixed cost_.
- $c$ is the _unit cost_.
- $D$ is the _demand_^[While the demand might be higher than the quantity produced, the company might sell only up to the latter.].

Profit is therefore a function of the inputs: $\mathrm{Profit} = f(p, c, D, Q, F)$. This model can be easily automated with a spreadsheet or a script, to analyse different scenario and compute the estimated profits.

# Monte Carlo methods

> In many cases we are _uncertain_ about some of the inputs in our calculations, altough we can assume that the input will follow a given distribution of values. This assumptions can be modeled mathematically using _stochastic variables_, instead of deterministic inputs and outputs.

How does this work in general?

We can assume that we have an _indipendently and identically distributed_ sample $(X_1, …, X_r)$ with a _known distribution_. What we wish to compute is $\mathbb{E}[g(X_1, …, X_r)]$, the expected value of a function of our set of stochastic variables.

We can build a new variable $Y = g((X_1, …, X_r)$, such that $\mu = \mathbb{E}[Y]$: for the _Law of Large Numbers_, we know that the sample mean of a sample of $n$ $iid$ random variables _converges to_ $\mu$ for $n \to \infty$.

In the example from @sec-profitex1, we have:

$$
Y = g(c, p, D, Q, F) = p \times min \{D, Q\} - (F + cQ)
$${#eq-profitstochastic}

If we repeatedly sample $c$, which is our $X_1$ for this particular model, we can derive a distribution of $\mathrm{Profit}$ and determine its mean under the uncertain condition of varying unit cost prices. Moreover, we can get other descriptive statistics to get a sense of the variability and other aspects of the resulting distribution^[Beware that the choice of the functiong $g()$ and the joint/marginal distributions of $X_1, …, X_r$ is _fundamental_ in determining the result and _should_ always be based on justifiable assumptions.].

## Using Past information: Distribution Fitting

> Not necessarily we have to assume a distribution for $X_1, …, X_r$: we might have _past information_ on at least one input variable.

Provided that this information is _reliable_ and _relevant_, we should use it:

1. We can sample from the past observation, if they cover all possible ranges.
2. We can _fit a distribution_ to the past observation and sample from the fitted distribution.

The second option uses the _method of moment estimation_ (MME), which is easy to implement, has a low computational cost, and yields estimates that are _consistent_^[They converge to the value of the parameter they are designed to estimate for $n \to \infty$.]. It is also called _moment matchin estimation_ because it aims to match the distribution and sample mean and variance^[The so-called first and second _moments_ of a distribution.].

The variability can be represented by choosing a distribution: for example, if $c \sim N(\mu, \sigma^2)$, then $\mathbb{E}[c] = \mu$ and $\mathbb{V}(c) = \sigma^2$.

The sample version of mean and variance are:

$$
\bar{y} = \frac{1}{n} \sum_{i = 1}^n y_i \qquad 
\mathrm{and} \qquad s^2 = \frac{1}{n} \sum_{i = 1}^n(y_i - \bar{y})^2
$${#eq-MMEnormal}

We will use this well-known formula to estimate $\hat \mu$ and $\hat \sigma$.

## Representing Variability: Distribution Fitting

> The estimated distribution can be used as the parent distribution from which we can generate sample values.

We can use several different distributions; in general, distributions are characterized by one or more parameter $\theta$.

Certain distributions are prevalent and well-suited for describing specific phenomena in various sub-fields. The following paragraphs contain a selection of common and uncommon probability distributions that can be used to represent the uncertainty associated to the input of a Monte Carlo simulation.

:::{.callout-caution}
When selecting a distribution for a Monte Carlo experiment, the shape and range of potential values must be carefully considered. 
Transforming vague information and expert knowledge into a usable distribution function for Monte Carlo experiments is a complex task, constituting an active area of research.
:::

### The Normal Distribution

The normal distribution is just one of many distributions one can use to represent variability for a input in a Monte Carlo experiment. Its main advantages is that it is fully parametrized by a _location_ and a _scale_ parameters, $\mu$ and $\sigma$. 

- $Y \sim N(\mu, \sigma^2)$.
- $\mathbb{E}(Y) = \mu$.
- $\mathbb{V}(Y) = \sigma^2$.
- Defined in $(-\infty, \infty)$.

```{r}
ggplot(
  data = data.frame(
    x = c(
      -5, 
      20
      )
    ), 
  aes(
    x
    )
  ) +
  stat_function(
     aes(
      color = "N(5,2)"
      ),
    fun = dnorm, 
    n = 101, 
    args = list(
      mean = 5, 
      sd = 2
      ),
    show.legend = T
    ) + 
  stat_function(
    aes(
      color = "N(12,2)"
      ),
    fun = dnorm, 
    n = 101, 
    args = list(
      mean = 12, 
      sd = 2
      ),
    show.legend = T
    ) + 
  stat_function(
     aes(
      color = "N(8,4)"
      ),
    fun = dnorm, 
    n = 101, 
    args = list(
      mean = 8, 
      sd = 4
      ),
    show.legend = T
    ) + 
  labs(
    title = "Normal Density",
    y = "Density"
    ) +
  scale_color_brewer(
    type = "div",
    palette = "Dark2"
  )
```

### The Gamma Distribution

- $Y \sim \Gamma(\alpha, \beta)$.
- Shape parameter: $\alpha > 0$.
- Rate parameter: $\beta > 0$.
- $\mathbb{E} = \alpha / \beta$.
- $\mathbb{V} = \alpha / \beta^2$.
- Defined in $(0, \infty)$.

To derive the MME we use the fact that:

$$
\alpha = \frac{\mathbb{E}(Y)^2}{\mathbb{V}(Y)} \qquad \mathrm{and}
\qquad \beta = \frac{\mathbb{E}(Y)}{\mathbb{V}(Y)}
$${#eq-MMEgamma}

```{r}
ggplot(
  data = data.frame(
    x = c(
      0, 
      8
      )
    ), 
  aes(
    x
    )
  ) +
  stat_function(
     aes(
      color = "Gamma(2,1)"
      ),
    fun = dgamma, 
    n = 101, 
    args = list(
      shape = 2, 
      rate = 1
      ),
    show.legend = T
    ) + 
  stat_function(
    aes(
      color = "Gamma(1,1)"
      ),
    fun = dgamma, 
    n = 101, 
    args = list(
      shape = 1, 
      rate = 1
      ),
    show.legend = T
    ) + 
  stat_function(
     aes(
      color = "Gamma(8,5)"
      ),
    fun = dgamma, 
    n = 101, 
    args = list(
      shape = 8, 
      rate = 5
      ),
    show.legend = T
    ) + 
  labs(
    title = "Gamma Density",
    y = "Density"
    ) +
  scale_color_brewer(
    type = "div",
    palette = "Dark2"
  )
```

### The Log-Normal Distribution

- Given $X \sim N(\mu, \sigma^2)$, then $Y = e^{X} \sim LN(\mu, \sigma^2)$.
- $\mathbb{E} = e^{\mu + \frac {\sigma^2}{2}}$.
- $\mathbb{V} = [e^{\sigma^2} - 1]e^{2 \mu + \sigma^2}$.
- Defined in $(0, \infty)$.

```{r}
ggplot(
  data = data.frame(
    x = c(
      0, 
      8
      )
    ), 
  aes(
    x
    )
  ) +
  stat_function(
     aes(
      color = "LN(1.8,0.9)"
      ),
    fun = dlnorm, 
    n = 101, 
    args = list(
      meanlog = 1.8, 
      sdlog = 0.9
      ),
    show.legend = T
    ) + 
  stat_function(
    aes(
      color = "LN(2.5,1.9)"
      ),
    fun = dlnorm, 
    n = 101, 
    args = list(
      meanlog = 2.5, 
      sdlog = 1.9
      ),
    show.legend = T
    ) + 
  stat_function(
     aes(
      color = "LN(2.2,1.4)"
      ),
    fun = dlnorm, 
    n = 101, 
    args = list(
      meanlog = 2.2, 
      sdlog = 1.4
      ),
    show.legend = T
    ) + 
  labs(
    title = "LogNormal Density",
    y = "Density"
    ) +
  scale_color_brewer(
    type = "div",
    palette = "Dark2"
  )
```

### The Uniform Distribution

- $Y \sim Unif(a, b)$.
- $a \in (-\infty, \infty)$.
- $b \in (a, \infty)$.
- Defined in $[a, b]$.

$$
\mathbb{E}(Y) = \frac{a + b}{2} \qquad \mathrm{and} \qquad 
\mathbb{V}(Y) = \frac{(b - a)^2}{12}
$${#eq-MMEgamma}

```{r}
ggplot(
  data = data.frame(
    x = c(
      -2, 
      5
      )
    ), 
  aes(
    x
    )
  ) +
  stat_function(
     aes(
      color = "U(0,1)"
      ),
    fun = dunif, 
    n = 101, 
    args = list(
      min = 0, 
      max = 1
      ),
    show.legend = T
    ) + 
  stat_function(
    aes(
      color = "U(0,2)"
      ),
    fun = dunif, 
    n = 101, 
    args = list(
      min = 0, 
      max = 2
      ),
    show.legend = T
    ) + 
  stat_function(
     aes(
      color = "U(-1.5,4)"
      ),
    fun = dunif, 
    n = 101, 
    args = list(
      min = -1.5, 
      max = 4
      ),
    show.legend = T
    ) + 
  labs(
    title = "Gamma Density",
    y = "Density"
    ) +
  scale_color_brewer(
    type = "div",
    palette = "Dark2"
  )
```

### The Beta Distribution

- $Y \sim Beta(\alpha, \beta)$.
- Shape parameters: $\alpha > 0$, $\beta > 0$.
- $Y$ takes values in $[0, 1]$, but it can be generalized to take values in any range $[a, b]$.

$$
\mathbb{E}(Y) = \frac{\alpha}{\alpha + \beta} \qquad \mathrm{and} 
\qquad \mathbb{V}(Y) = \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
$${#eq-beta}

We can also have a 4-parameters $Beta$ distribution: $B = Y (b - a) + a$. Then: $B \sim GBeta(\alpha, \beta, a, b)$.

$$
\mathbb{E}(B) = \frac{\alpha b + \beta a}{\alpha + \beta} \qquad \mathrm{and} 
\qquad \mathbb{V}(B) = \frac{\alpha \beta (b - a)^2}{(\alpha  + \beta)^2 (\alpha + \beta + 1)}
$${#eq-gbeta}

```{r}
ggplot(
  data = data.frame(
    x = c(
      0, 
      1.5
      )
    ), 
  aes(
    x
    )
  ) +
  stat_function(
     aes(
      color = "GBeta(0.8, 3, 0, 1.2)"
      ),
    fun = gbeta::dgbeta, 
    n = 101, 
    args = list(
      c = 0.8, 
      d = 3,
      kappa = 0,
      tau = 1.2
      ),
    show.legend = T
    ) + 
  stat_function(
    aes(
      color = "GBeta(4, 4, 0, 1)"
      ),
    fun = gbeta::dgbeta, 
    n = 101, 
    args = list(
      c = 4, 
      d = 4,
      kappa = 0,
      tau = 1
      ),
    show.legend = T
    ) + 
  stat_function(
     aes(
      color = "GBeta(1, 1, 0.2, 1.2)"
      ),
    fun = gbeta::dgbeta, 
    n = 101, 
    args = list(
      c = 1, 
      d = 1,
      kappa = .2,
      tau = 1.2
      ),
    show.legend = T
    ) + 
  stat_function(
     aes(
      color = "GBeta(3, 0.8, 0, 0.7)"
      ),
    fun = gbeta::dgbeta, 
    n = 101, 
    args = list(
      c = 3, 
      d = .8,
      kappa = 0,
      tau = .7
      ),
    show.legend = T
    ) + 
  labs(
    title = "Generalized Beta Density",
    y = "Density"
    ) +
  scale_color_brewer(
    type = "div",
    palette = "Dark2"
  )
```

### The Triangular Distribution

- $Y \sim Tri(a, b, c)$; it takes values in $[a,b]$ and has a mode at $c$.
- $a \in (-\infty, \infty)$ is the minimum, $b \in (a, \infty)$ the maximum, $c \in [a, b]$ is the mode.

$$
\mathbb{E}(Y) = \frac{a + b + c}{3} \qquad \mathrm{and} 
\mathbb{V}(Y) = \frac{a^2 + b^2 c^2 - ab - ac - bc}{18}
$${#eq-triang}

```{r}
ggplot(
  data = data.frame(
    x = c(
      -2, 
      5
      )
    ), 
  aes(
    x
    )
  ) +
  stat_function(
     aes(
      color = "Tri(−1,1,0)"
      ),
    fun = EnvStats::dtri, 
    n = 101, 
    args = list(
      min = -1,
      max = 1,
      mode = 0
      ),
    show.legend = T
    ) + 
  stat_function(
    aes(
      color = "Tri(−2,2,0)"
      ),
    fun = EnvStats::dtri, 
    n = 101, 
    args = list(
      min = -2,
      max = 2,
      mode = 0
      ),
    show.legend = T
    ) + 
  stat_function(
     aes(
      color = "Tri(−2,5,3)"
      ),
    fun = EnvStats::dtri, 
    n = 101, 
    args = list(
      min = -2,
      max = 5,
      mode = 3
      ),
    show.legend = T
    ) + 
  labs(
    title = "Triangular Density",
    y = "Density"
    ) +
  scale_color_brewer(
    type = "div",
    palette = "Dark2"
  )
```

### The PERT Distribution

The PERT distribution is a re-parametrization of the $GBeta$ distribution in which the range and mode are specified.

- $Y \sim PERT(a, b, c)$; it takes values in $[a,b]$ and has a mode at $c$.
- $a \in (-\infty, \infty)$ is the minimum, $b \in (a, \infty)$ the maximum, $c \in [a, b]$ is the mode.

$$
\mathbb{E}(Y) = \frac{a + b + 4c}{6} \qquad \mathrm{and} 
\mathbb{V}(Y) = \frac{(\mu - a)(c - \mu)}{7}
$${#eq-PERT}

```{r}
ggplot(
  data = data.frame(
    x = c(
      -2, 
      5
      )
    ), 
  aes(
    x
    )
  ) +
  stat_function(
     aes(
      color = "PERT(−1,1,0)"
      ),
    fun = mc2d::dpert, 
    n = 101, 
    args = list(
      min = -1,
      max = 1,
      mode = 0
      ),
    show.legend = T
    ) + 
  stat_function(
    aes(
      color = "PERT(−2,2,0)"
      ),
    fun = mc2d::dpert, 
    n = 101, 
    args = list(
      min = -2,
      max = 2,
      mode = 0
      ),
    show.legend = T
    ) + 
  stat_function(
     aes(
      color = "Pert(−2,5,3)"
      ),
    fun = mc2d::dpert, 
    n = 101, 
    args = list(
      min = -2,
      max = 5,
      mode = 3
      ),
    show.legend = T
    ) + 
  labs(
    title = "Triangular Density",
    y = "Density"
    ) +
  scale_color_brewer(
    type = "div",
    palette = "Dark2"
  )
```

### Discrete Distributions

> Up to this point, the covered distributions were applicable to any _real value_ in the interval [a, b], suitable for variables measured on a _continuous scale_^[Cost, height, time, mileage, etc.]. However, certain variables can only assume _discrete values_, such as the number of passengers on a bus, vacant rooms in a hotel. Various distributions are designed to capture the potential variability of random variables constrained to discrete values.

```{r}
x <-  seq(
  0,
  30
  )

ggplot(
  data = data.frame(
    x = x,
    y = dbinom(x, size = 30, prob = .5)
    ), 
  aes(
    x = as_factor(x),
    y
    )
  ) +
  geom_col() +
  labs(
    title = "Binomial Density for Bin(30, .5",
    x = "Number of Successes",
    y = "Density"
    )
```

# Example 1: _Outsourcing or Not_?